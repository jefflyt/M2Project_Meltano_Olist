# Meltano Olist ETL Project

This is the core Meltano project for the Olist E-commerce Data Pipeline. It handles the extraction, transformation, and loading of Olist e-commerce data from PostgreSQL to Google BigQuery.

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Google Cloud service account with BigQuery permissions
- Supabase PostgreSQL database access

### Setup
1. **Install dependencies:**
   ```bash
   meltano install
   ```

2. **Configure credentials:**
   ```bash
   export GOOGLE_APPLICATION_CREDENTIALS="/path/to/your/credentials.json"
   ```

3. **Run the pipeline:**
   ```bash
   ./run_pipeline.sh
   ```

## ğŸ“Š Data Pipeline

### Source: PostgreSQL (Supabase)
- **Host:** aws-1-ap-southeast-1.pooler.supabase.com
- **Database:** postgres
- **Schema:** public
- **Tables:** All Olist e-commerce datasets

### Target: Google BigQuery
- **Project:** extended-legend-470014-n7
- **Dataset:** olist_raw
- **Method:** Batch loading with denormalization

## ğŸ”§ Configuration

### Environment Variables
- `GOOGLE_APPLICATION_CREDENTIALS`: Path to BigQuery service account key
- `TAP_POSTGRES_PASSWORD`: PostgreSQL database password (stored in .env)

### Meltano Configuration
See `meltano.yml` for detailed plugin configurations including:
- PostgreSQL connection settings
- BigQuery credentials and dataset configuration
- Batch processing parameters

## ğŸ“ Project Structure

```
meltano-olist/
â”œâ”€â”€ meltano.yml              # Main Meltano configuration
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ run_pipeline.sh         # Pipeline execution script
â”œâ”€â”€ test_bigquery.py        # BigQuery connection test
â”œâ”€â”€ .env                    # Environment variables
â”œâ”€â”€ .gitignore             # Git ignore patterns
â”œâ”€â”€ .meltano/              # Meltano internal files
â”œâ”€â”€ analyze/               # Data analysis scripts
â”œâ”€â”€ extract/               # Extraction configurations
â”œâ”€â”€ load/                  # Loading configurations
â”œâ”€â”€ transform/             # Data transformation logic
â”œâ”€â”€ notebook/              # Jupyter notebooks
â”œâ”€â”€ orchestrate/           # Orchestration scripts
â””â”€â”€ output/                # Pipeline outputs and logs
```

## ğŸ§ª Testing

### Test BigQuery Connection
```bash
python test_bigquery.py
```

### Test PostgreSQL Connection
```bash
meltano config tap-postgres test
```

### Test Individual Components
```bash
meltano invoke tap-postgres --about
meltano invoke target-bigquery --help
```

## ğŸ“ˆ Monitoring

- **Pipeline Status:** `meltano state`
- **Logs:** `meltano logs`
- **BigQuery Jobs:** Google Cloud Console â†’ BigQuery â†’ Job History

## ğŸ”„ Pipeline Execution

### Manual Execution
```bash
meltano run tap-postgres target-bigquery
```

### Automated Execution
```bash
./run_pipeline.sh
```

### Custom Execution
```bash
# Run with specific environment
meltano run --environment=prod tap-postgres target-bigquery

# Run with debug logging
meltano --log-level=debug run tap-postgres target-bigquery
```

## ğŸ› Troubleshooting

### Common Issues

1. **BigQuery Authentication Error:**
   ```bash
   export GOOGLE_APPLICATION_CREDENTIALS="/correct/path/to/credentials.json"
   ```

2. **PostgreSQL Connection Error:**
   - Check credentials in `meltano.yml`
   - Verify Supabase connection string
   - Check network connectivity

3. **Dataset Not Found:**
   ```bash
   bq mk --dataset extended-legend-470014-n7:olist_raw
   ```

### Debug Mode
```bash
meltano --log-level=debug run tap-postgres target-bigquery
```

## ğŸ“š Resources

- [Meltano Documentation](https://docs.meltano.com/)
- [Google BigQuery Documentation](https://cloud.google.com/bigquery/docs)
- [Supabase Documentation](https://supabase.com/docs)
- [Olist Dataset Documentation](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)

## ğŸ¤ Contributing

1. Test your changes locally
2. Update documentation as needed
3. Follow the existing code style
4. Create descriptive commit messages

---

**Last Updated:** August 30, 2025
