# Meltano Configuration for Olist E-commerce Data Extraction
# ==========================================================
#
# This configuration defines a simple ETL pipeline that extracts data from
# PostgreSQL (Supabase) and loads it into Google BigQuery raw dataset.
#
# Purpose: Data extraction only - no transformations or analytics
# Pipeline: tap-postgres → target-bigquery → olist_raw dataset
#
# Author: M2Project Team
# Last Updated: August 31, 2025
# ==========================================================

version: 1

# Default environment for pipeline execution
default_environment: dev

# Unique project identifier
project_id: b8644576-3b67-453a-8f52-fe664f1834b7

# Single environment - this is a simple extraction pipeline
environments:
- name: dev        # Single environment for extraction pipeline

# Plugin configurations
plugins:
  # Data Extractor - PostgreSQL (Supabase)
  extractors:
  - name: tap-postgres
    variant: meltanolabs
    pip_url: meltanolabs-tap-postgres
    config:
      database: postgres    # PostgreSQL connection settings for Supabase
      filter_schemas:
        - public            # Extract only from public schema
      port: 5432
      user: postgres.wfpaqulgzvxvyosikwmj
      host: aws-1-ap-southeast-1.pooler.supabase.com
      # Password set via environment variable: TAP_POSTGRES_PASSWORD

  # Data Loader - BigQuery Raw Dataset
  loaders:
  - name: target-bigquery
    variant: z3z1ma
    pip_url: git+https://github.com/z3z1ma/target-bigquery.git
    config:
      project: 'extended-legend-470014-n7'  # BigQuery raw dataset configuration
      dataset: olist_raw                    # Raw data storage
      # Authentication
      credentials_path: /Users/jefflee/SCTP/M2Project/extended-legend-470014-n7-db75dec7d87a.json
      # Data loading settings
      batch_size: 104857600               # 100MB batches
      method: batch_job                   # Efficient batch loading
      denormalized: true                  # Flatten nested structures
      flattening_enabled: true
      flattening_max_depth: 1

# Pipeline definition - simple extract and load
schedules:
- name: daily_extract
  job: tap-postgres target-bigquery
  interval: "@daily"

# Notes:
# - This is a simple data extraction pipeline - no transformations
# - All data transformations are handled separately by dbt in dbt_clean_olist/
# - Raw data goes to BigQuery olist_raw dataset
# - Credentials and passwords should be set via environment variables
# - Run with: meltano run tap-postgres target-bigquery
